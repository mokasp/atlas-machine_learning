# Machine Learning Foundations
This repository is a representation of what I have learned during my time in the Atlas School Machine Learning program.

| Tables                | overview           | repos  |
| :-----------          |:------------- | :-----|
| Math                  | Covers essential mathematical concepts crucial for machine learning. Calculus is pivotal for optimizing models through gradient-based methods, enabling effective training and fine-tuning of algorithms. Linear algebra is fundamental for manipulating and understanding high-dimensional data, crucial for algorithms involving vectors and matrices, such as neural networks and dimensionality reduction techniques. Probability provides the theoretical foundation for handling uncertainty and making inferences from data, underpinning many machine learning methods including probabilistic models and statistical analysis. ||
| supervised_learning   | <fill in>      | - RNNs <br> - classification <br> - cnn <br> - deep_cnns <br> - Error_analysis <br> - keras <br> - nlp_metrics <br> - object_detection <br> - optimization <br> - regularization <br> - tensorflow <br> - time_series <br> - transfer_learning <br> - word_embeddings |
| unsupervised_learning | <fill in>      | - autoencoders <br> - clustering <br> - dimensionality_reduction <br> - Hmm <br> - Hyperparameter_tuning |


## Math
This nested repo covers essential mathematical concepts related to machine learning. The main mathematical framework behind most machine learning algorithms are Calculus, Linear Algebra, and Probability and statistics. Calculus is pivotal for optimizing models through gradient-based methods, enabling effective training and fine-tuning of algorithms. Linear algebra is fundamental for manipulating and understanding high-dimensional data, crucial for algorithms involving vectors and matrices, such as neural networks and dimensionality reduction techniques. Probability provides the theoretical foundation for handling uncertainty and making inferences from data, underpinning many machine learning methods including probabilistic models and statistical analysis.
### Concepts
- [advanced_linear_algebra](https://github.com/mokasp/atlas-machine_learning/tree/main/math/advanced_linear_algebra): techniques and concepts beyond basic linear algebra, crucial for understanding more complex algorithms.
- [Bayesian_prob](https://github.com/mokasp/atlas-machine_learning/tree/main/math/bayesian_prob): The Bayesian approach to probability, which is fundamental for probabilistic models and inference.
- [calculus](https://github.com/mokasp/atlas-machine_learning/tree/main/math/calculus): Calculus concepts, including differentiation and integration, which are essential for optimization in machine learning.
- [convolutions_and_pooling](https://github.com/mokasp/atlas-machine_learning/tree/main/math/linear_algebra):  Mathematical operations used in convolutional neural networks (CNNs) for processing image data.
- [linear_algebra](https://github.com/mokasp/atlas-machine_learning/tree/main/math/linear_algebra): Basics of linear algebra, including vectors, matrices, and tensor operations.
- [multivariate_prob](https://github.com/mokasp/atlas-machine_learning/tree/main/math/multivariate_prob): Probability theory involving multiple variables, important for understanding joint distributions and multivariate models.
- [plotting](https://github.com/mokasp/atlas-machine_learning/tree/main/math/plotting): Techniques for visualizing data and model performance.
- [probability](https://github.com/mokasp/atlas-machine_learning/tree/main/math/probability): Basic probability theory and concepts, foundational for understanding many machine learning algorithms.

## Supervised Learning
### Concepts
- RNNs
- classification
- cnn
- deep_cnns
- Error_analysis
- keras
- nlp_metrics
- object_detection
- optimization
- regularization
- tensorflow
- time_series
- transfer_learning
- word_embeddings
