# Machine Learning Foundations
This repository is a representation of what I have learned during my time in the Atlas School Machine Learning program.


## Math
This nested repo covers essential mathematical concepts related to machine learning. The main mathematical framework behind most machine learning algorithms are Calculus, Linear Algebra, and Probability and statistics. Calculus is pivotal for optimizing models through gradient-based methods, enabling effective training and fine-tuning of algorithms. Linear algebra is fundamental for manipulating and understanding high-dimensional data, crucial for algorithms involving vectors and matrices, such as neural networks and dimensionality reduction techniques. Probability provides the theoretical foundation for handling uncertainty and making inferences from data, underpinning many machine learning methods including probabilistic models and statistical analysis.
### Concepts
- [advanced_linear_algebra](https://github.com/mokasp/atlas-machine_learning/tree/main/math/advanced_linear_algebra): techniques and concepts beyond basic linear algebra, crucial for understanding more complex algorithms.
- [Bayesian_prob](https://github.com/mokasp/atlas-machine_learning/tree/main/math/bayesian_prob): The Bayesian approach to probability, which is fundamental for probabilistic models and inference.
- [calculus](https://github.com/mokasp/atlas-machine_learning/tree/main/math/calculus): Calculus concepts, including differentiation and integration, which are essential for optimization in machine learning.
- [convolutions_and_pooling](https://github.com/mokasp/atlas-machine_learning/tree/main/math/linear_algebra):  Mathematical operations used in convolutional neural networks (CNNs) for processing image data.
- [linear_algebra](https://github.com/mokasp/atlas-machine_learning/tree/main/math/linear_algebra): Basics of linear algebra, including vectors, matrices, and tensor operations.
- [multivariate_prob](https://github.com/mokasp/atlas-machine_learning/tree/main/math/multivariate_prob): Probability theory involving multiple variables, important for understanding joint distributions and multivariate models.
- [plotting](https://github.com/mokasp/atlas-machine_learning/tree/main/math/plotting): Techniques for visualizing data and model performance.
- [probability](https://github.com/mokasp/atlas-machine_learning/tree/main/math/probability): Basic probability theory and concepts, foundational for understanding many machine learning algorithms.

## Supervised Learning
This repo covers techniques where models are trained on labeled data to make predictions or classifications. Supervised learning methods utilize algorithms like neural networks to learn from examples and generalize to new, unseen data. Key areas include the development and training of models using frameworks like TensorFlow and Keras, optimization strategies for improving model performance, and evaluation metrics for assessing accuracy. Topics also encompass advanced neural network architectures, including convolutional and recurrent networks, for tasks such as image recognition and time series prediction.
### Concepts
- [RNNs](https://github.com/mokasp/atlas-machine_learning/tree/main/supervised_learning/RNNs): A type of neural network designed for sequential data and time series.
- [classification](https://github.com/mokasp/atlas-machine_learning/tree/main/supervised_learning/classification): Techniques for categorizing data into predefined classes.
- [cnn](https://github.com/mokasp/atlas-machine_learning/tree/main/supervised_learning/cnn): Neural networks designed for processing grid-like data, such as images.
- [deep_cnns](https://github.com/mokasp/atlasmachine_learning/tree/main/supervised_learning/convolutions_and_pooling): Advanced CNN architectures with multiple layers for complex image processing tasks.
- [Error_analysis](https://github.com/mokasp/atlas-machine_learning/tree/main/supervised_learning/error_analysis): Methods for analyzing and understanding errors in model predictions.
- [keras](https://github.com/mokasp/atlas-machine_learning/tree/main/supervised_learning/keras):  A high-level neural networks API, written in Python, for building and training deep learning models.
- [nlp_metrics](https://github.com/mokasp/atlas-machine_learning/tree/main/supervised_learning/nlp_metrics): Metrics used for evaluating natural language processing tasks.
- [object_detection](https://github.com/mokasp/atlas-machine_learning/tree/main/supervised_learning/object_detection): Techniques for detecting and localizing objects within images.
- [optimization](https://github.com/mokasp/atlas-machine_learning/tree/main/supervised_learning/optimization): Methods for improving model performance by tuning parameters and minimizing loss functions.
- [regularization](https://github.com/mokasp/atlas-machine_learning/tree/main/supervised_learning/regularization):  Techniques to prevent overfitting and improve model generalization.
- [tensorflow](https://github.com/mokasp/atlas-machine_learning/tree/main/supervised_learning/tensorflow): An open-source framework for building and deploying machine learning models.
- [time_series](https://github.com/mokasp/atlas-machine_learning/tree/main/supervised_learning/time_series): Techniques for analyzing and predicting time-dependent data.
- [transfer_learning](https://github.com/mokasp/atlas-machine_learning/tree/main/supervised_learning/transfer_learning): Using pre-trained models on new but related tasks to improve performance.
- [word_embeddings](https://github.com/mokasp/atlas-machine_learning/tree/main/supervised_learning/word_embeddings): Techniques for representing words in vector space for NLP tasks.


## Unsupervised Learning
This repo focuses on techniques used to identify patterns and structure from unlabeled data. Unsupervised learning methods aim to identify underlying structures in the data without predefined labels. Key areas include clustering algorithms for grouping similar data points, dimensionality reduction techniques to simplify complex data, and autoencoders for feature learning and data reconstruction. Hidden Markov Models (HMMs) are used for sequential data analysis, while hyperparameter tuning is essential for optimizing model performance. 
### Concepts
- [autoencoders](https://github.com/mokasp/atlas-machine_learning/tree/main/unsupervised_learning/autoencoders): Neural networks designed for unsupervised learning tasks like dimensionality reduction and feature learning.
- [clustering](https://github.com/mokasp/atlas-machine_learning/tree/main/unsupervised_learning/clustering): Methods for grouping data points into clusters based on similarity.
- [dimensionality_reduction](https://github.com/mokasp/atlas-machine_learning/tree/main/unsupervised_learning/dimensionality_reduction): Techniques for reducing the number of features in data while preserving important information.
- [Hmm](https://github.com/mokasp/atlas-machine_learning/tree/main/unsupervised_learning/hmm): Statistical models that describe systems with hidden states, useful for time series and sequential data.
- [Hyperparameter_tuning](https://github.com/mokasp/atlas-machine_learning/tree/main/unsupervised_learning/hyperparameter_tuning): The process of optimizing hyperparameters to improve model performance.
